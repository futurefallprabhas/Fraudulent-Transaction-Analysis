{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futurefallprabhas/Fraudulent-Transaction-Analysis/blob/codespace-jubilant-waddle-g445w6grq4xph6jr/Assignment1_Set1_2_ML_14_Mar_RJ_v4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHlhoSpr_pxy"
      },
      "source": [
        "### 1. Import Libraries/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "e_yaZF8ffLMV",
        "outputId": "5ce157f9-6521-406b-8404-1201d19aa250"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rajkumar\\\\Desktop\\\\GoldenVisa\\\\DataScience-Bits-Pilani\\\\Mtech-Course-Start\\\\2-semester-start-real\\\\1-Machine Learning-DSECLZG565\\\\Assignments\\\\Assignment1\\\\Financial_Transaction.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-368b4f860e1a>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#data=pd.read_csv('ML_Assignment_1.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#data = pd.read_csv(r'D:\\mtech_bits_pilani\\sem2\\ml\\assignment\\Assignment 1 Set 1 Dataset.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Users\\\\Rajkumar\\\\Desktop\\\\GoldenVisa\\\\DataScience-Bits-Pilani\\\\Mtech-Course-Start\\\\2-semester-start-real\\\\1-Machine Learning-DSECLZG565\\\\Assignments\\\\Assignment1\\\\Financial_Transaction.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Rajkumar\\\\Desktop\\\\GoldenVisa\\\\DataScience-Bits-Pilani\\\\Mtech-Course-Start\\\\2-semester-start-real\\\\1-Machine Learning-DSECLZG565\\\\Assignments\\\\Assignment1\\\\Financial_Transaction.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "#data=pd.read_csv('ML_Assignment_1.csv')\n",
        "#data = pd.read_csv(r'D:\\mtech_bits_pilani\\sem2\\ml\\assignment\\Assignment 1 Set 1 Dataset.csv')\n",
        "data = pd.read_csv('C:\\\\Users\\\\Rajkumar\\\\Desktop\\\\GoldenVisa\\\\DataScience-Bits-Pilani\\\\Mtech-Course-Start\\\\2-semester-start-real\\\\1-Machine Learning-DSECLZG565\\\\Assignments\\\\Assignment1\\\\Financial_Transaction.csv',index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdOa_CawhevG"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnPpiniN_px7"
      },
      "source": [
        "### 2. Data Visualization and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buKe5bkz_px7"
      },
      "source": [
        "#### a. Print 2 rows for sanity check to identify all the features present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvPUl1RShi8V"
      },
      "outputs": [],
      "source": [
        "# a.Print the first 2 rows of the dataset\n",
        "data.head(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM1dwcBvjMAJ"
      },
      "outputs": [],
      "source": [
        "data.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5smLZOBajwa3"
      },
      "outputs": [],
      "source": [
        "class_counts = data['Is Fraudulent'].value_counts()\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BD9rptd_px-"
      },
      "source": [
        "#### b. Comment on class imbalance with appropriate visualization method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qclbowpj3M3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Count the occurrences of each class\n",
        "class_counts = data['Is Fraudulent'].value_counts()\n",
        "\n",
        "# Plot the distribution of classes\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
        "plt.title('Distribution of Classes')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([0, 1], ['Non-Fraudulent', 'Fraudulent'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNvGuOKM_px_"
      },
      "source": [
        "Class Imbalance:\n",
        "As we can see from the above image , the non-fraudlent class makes up the majority class and the fraudulent makes up the minority class. Hence our data set is imbalanced, that can result to biased predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgJ0iG1a_pyA"
      },
      "outputs": [],
      "source": [
        "#Get instances of fraud and normal transactions\n",
        "fraud = data[data['Is Fraudulent'] == 1]\n",
        "no_fraud = data[data['Is Fraudulent'] == 0]\n",
        "print(\"There are\", len(fraud), \"instances of fraud\")\n",
        "print(\"There are\", len(no_fraud), \"normal transactions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4sLeY5I_pyA"
      },
      "outputs": [],
      "source": [
        "#Get summary statistics for the amount paid\n",
        "fraud.Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axBvVghe_pyB"
      },
      "outputs": [],
      "source": [
        "no_fraud.Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LBXMlmy_pyC"
      },
      "outputs": [],
      "source": [
        "#Compare both transaction values\n",
        "data.groupby('Is Fraudulent').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEPQwsTj_pyD"
      },
      "source": [
        "#### C. Provide appropriate data visualizations to get an insight about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNWigdYHkRqX"
      },
      "outputs": [],
      "source": [
        "# Histogram for numerical features\n",
        "data.hist(figsize=(12, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdjohG5lkh0N"
      },
      "outputs": [],
      "source": [
        "# Count plot for categorical features\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Card Type', data=data)\n",
        "plt.title('Count of Transactions by Card Type')\n",
        "plt.xlabel('Card Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-wM8EEVktsX"
      },
      "outputs": [],
      "source": [
        "# Box plot of 'Amount' by 'Is Fraudulent'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Is Fraudulent', y='Amount', data=data)\n",
        "plt.title('Amount Distribution by Fraudulent Status')\n",
        "plt.xlabel('Is Fraudulent')\n",
        "plt.ylabel('Amount')\n",
        "plt.xticks([0, 1], ['Non-Fraudulent', 'Fraudulent'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3HPhF25k04U"
      },
      "outputs": [],
      "source": [
        "#Visualize pairwise relationships between numerical features and the target variable\n",
        "sns.pairplot(data, hue='Is Fraudulent', vars=['Amount', 'Previous Transactions', 'Balance Before Transaction'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DoMwzU0_pyF"
      },
      "source": [
        "#### d. Do the correlational analysis on the dataset. Provide a visualization for the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNKE2kDIlAIY"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Z27W0c_pyG"
      },
      "source": [
        "Justification :\n",
        "Correlation analysis helps us in providing the following insights while doing feature engineering:\n",
        "    Features with high correlation are more linearly dependent and hence have almost the same effect on the dependent variable. So, when two features have high correlation, we can drop one of the two features. This analysis helps is identifying those redundant features.\n",
        "    Helps idetify the featuers that are highly correlated with the target variable. Using these features have a significant impact on the outcome.\n",
        "    Correlation analysis helps in detecting multicollinearity, which occurs when independent variables are highly correlated with each other. Multicollinearity can cause issues in regression analysis, making it difficult to determine the effect of each variable independently. In such cases, you might choose to remove one of the correlated variables during feature selection to alleviate multicollinearity.\n",
        "    Correlation analysis can aid in dimensionality reduction by selecting a subset of features that are most relevant for prediction while discarding less informative or redundant features. This can lead to simpler and more interpretable models.\n",
        "\n",
        "    Each cell in the heatmap represents the correlation coefficient between two variables. The values range from -1 to 1, where:\n",
        "•\t1 indicates a perfect positive correlation\n",
        "\n",
        "•\t-1 indicates a perfect negative correlation\n",
        "\n",
        "•\t0 indicates no correlation\n",
        "\n",
        "Now, regarding the effect of correlational analysis on feature selection:\n",
        "1.\tIdentifying Redundant Features: Highly correlated features may provide redundant information. In feature selection, redundant features can be eliminated to reduce model complexity and improve interpretability without sacrificing predictive performance.\n",
        "2.\tAvoiding Multicollinearity: Correlated features can lead to multicollinearity, which can destabilize model coefficients and make the model's estimates less reliable. Removing one of the highly correlated features can mitigate multicollinearity issues.\n",
        "3.\tImproving Model Performance: Removing irrelevant or redundant features based on correlational analysis can lead to better model performance by focusing on the most informative features. It helps in building simpler and more interpretable models, reducing the risk of overfitting and improving generalization to unseen data.\n",
        "\n",
        "In summary, correlational analysis plays a crucial role in feature selection by helping to identify and remove redundant or irrelevant features, thereby improving model performance, interpretability, and generalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OU4GTb6l8Dq"
      },
      "source": [
        "## 3. Data Pre-processing and cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX3qvxnH_pyI"
      },
      "source": [
        "#### a. Do the appropriate pre-processing of the data like identifying NULL or Missing Values if any, handling of outliers if present in the dataset, skewed data etc. Mention the pre-processing steps performed in the markdown cell. Explore few latest data balancing tasks and its effect on model evaluation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzxYlifql4KJ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vuh_jv7XmKRX"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDzu3QiF_pyJ"
      },
      "source": [
        "Financial Transaction data set has no null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I682fkjY_pyJ"
      },
      "outputs": [],
      "source": [
        "print(\"Financial Transaction data set has\", data.isnull().values.sum(), \"missing values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqWgG3dpmQAk",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsqMXbPP_pyK"
      },
      "source": [
        "#### Checking outliers using boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yDzTTYOE_pyK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# List of columns to exclude from the boxplot generation\n",
        "columns_to_exclude = ['Is Fraudulent']\n",
        "\n",
        "\n",
        "# Combine columns to exclude\n",
        "columns_to_exclude.extend(categorical_columns)\n",
        "\n",
        "num_cols_per_row = 3  # Define num_cols_per_row before the loop\n",
        "plot_count = 0  # Initialize plot_count before the loop\n",
        "\n",
        "for column in data.columns:\n",
        "    if column not in columns_to_exclude:  # Exclude specified columns\n",
        "        if data[column].nunique() > 1:  # Ensure the column has more than one unique value\n",
        "            # Create a new row of plots if the number of plots in the current row exceeds num_cols_per_row\n",
        "            if plot_count % num_cols_per_row == 0:\n",
        "                fig, axes = plt.subplots(1, num_cols_per_row, figsize=(15, 5))  # Adjust the figure size as needed\n",
        "            # Generate boxplot and add it to the current row\n",
        "            data[[column]].boxplot(ax=axes[plot_count % num_cols_per_row])\n",
        "            axes[plot_count % num_cols_per_row].set_title('Boxplot of ' + column)\n",
        "            axes[plot_count % num_cols_per_row].set_ylabel('Value')\n",
        "            plot_count += 1\n",
        "            # Add marks for outliers\n",
        "            outliers = data[column][data[column] > data[column].quantile(0.75) + 1.5 * (data[column].quantile(0.75) - data[column].quantile(0.25))]\n",
        "            axes[plot_count % num_cols_per_row].scatter([1] * len(outliers), outliers, color='red', marker='o')  # Add red circles for outliers\n",
        "            # Save the figure when the row is complete\n",
        "            if plot_count % num_cols_per_row == 0:\n",
        "                plt.tight_layout()\n",
        "                #plt.savefig(f'boxplots_row_{plot_count // num_cols_per_row}.png')  # Save each row of boxplots as an image\n",
        "                #plt.close()  # Close the current figure to release memory\n",
        "\n",
        "# Save the remaining plots if they don't fill a complete row\n",
        "if plot_count % num_cols_per_row != 0:\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(f'boxplots_row_{plot_count // num_cols_per_row + 1}.png')  # Save the last row of boxplots as an image\n",
        "    #plt.close()  # Close the current figure to release memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KhP6E-9Q_pyL"
      },
      "outputs": [],
      "source": [
        "outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MCTsbuf_pyN"
      },
      "source": [
        "no outliers found for the given data from the boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7qKwIak_pyN"
      },
      "outputs": [],
      "source": [
        "#### Code to check for outliers based on IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6w_n1AP_pyN"
      },
      "outputs": [],
      "source": [
        "# Identify categorical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# List of columns to exclude from the boxplot generation\n",
        "columns_to_exclude = ['Is Fraudulent']\n",
        "\n",
        "# Combine columns to exclude\n",
        "columns_to_exclude.extend(categorical_columns)\n",
        "\n",
        "# Function to detect outliers using the IQR method\n",
        "def detect_outliers_iqr(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = (series < lower_bound) | (series > upper_bound)\n",
        "    return outliers\n",
        "\n",
        "# Detect outliers in all columns\n",
        "outliers = data.drop(columns=columns_to_exclude).apply(detect_outliers_iqr)\n",
        "\n",
        "# Flag to track if any outliers were found\n",
        "outliers_found = False\n",
        "\n",
        "# Print columns with outliers\n",
        "for column in outliers.columns:\n",
        "    if outliers[column].any():\n",
        "        outliers_found = True\n",
        "        print(f\"Outliers detected in column '{column}':\")\n",
        "        print(data[outliers[column]])\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Print message if no outliers were found\n",
        "if not outliers_found:\n",
        "    print(\"No outliers detected in any column.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "M-ATCRed_pyO"
      },
      "outputs": [],
      "source": [
        "# Identify categorical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# List of columns to exclude from the boxplot generation\n",
        "columns_to_exclude = ['Is Fraudulent']\n",
        "\n",
        "# Combine columns to exclude\n",
        "columns_to_exclude.extend(categorical_columns)\n",
        "\n",
        "\n",
        "# Calculate skewness for each specified column\n",
        "skewness = data.drop(columns=columns_to_exclude).skew()\n",
        "\n",
        "# Print column name and skewness for each specified column\n",
        "for column, skew in skewness.items():\n",
        "    print(f\"Skewness for {column}: {skew}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeEdZMpn_pyP"
      },
      "source": [
        "#### The skweness has been calculated for all columns and it is found that the values are near to 0 and hence values\n",
        "#### of the columns are uniformily distributed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG-1O7SK_pyP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Spending Patterns'], kde=True, color='blue', bins=75)  # You can adjust the number of bins for better visualization\n",
        "plt.title('Spending Patterns')\n",
        "plt.xlabel('Spending Pattern')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWI3jfvU_pyl"
      },
      "outputs": [],
      "source": [
        "financial_data_1 = data[\"Spending Patterns\"]\n",
        "financial_data_2 = data[\"Previous Transactions\"]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(financial_data_1)\n",
        "plt.xlabel(\"Financial Data\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Box Plot based on Spending patterns\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL9etUtJ_pyl"
      },
      "outputs": [],
      "source": [
        "#subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "#fraud transactions\n",
        "sns.histplot(data[data['Is Fraudulent'] == 1]['Time of Day'], bins=50, kde=True, color='red', label='Fraud', ax=ax1)\n",
        "ax1.set_title('Transaction Time of day for Fraud Transactions')\n",
        "ax1.set_xlabel('Time in Hours')\n",
        "ax1.set_ylabel('Number of Transactions')\n",
        "ax1.legend()\n",
        "\n",
        "#normal transactions\n",
        "sns.histplot(data[data['Is Fraudulent'] == 0]['Time of Day'], bins=50, kde=True, color='blue', label='Normal', ax=ax2)\n",
        "ax2.set_title('Transaction Times for Normal Transactions')\n",
        "ax2.set_xlabel('Time in Days')\n",
        "ax2.set_ylabel('Number of Transactions')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrqIbydr_pym"
      },
      "source": [
        "b.Apply appropriate feature engineering techniques for them. Apply the feature transformation techniques like Standardization, Normalization, etc. You are free to apply the appropriate transformations depending upon the structure and the complexity of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxCcUlbw_pym"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih8pzI9b_pyn"
      },
      "outputs": [],
      "source": [
        "data_cat = data.select_dtypes('object')\n",
        "data_num = data.select_dtypes(np.number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RZKWB2R_pyn"
      },
      "outputs": [],
      "source": [
        "data_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oUFrkcM_pyo"
      },
      "outputs": [],
      "source": [
        "data_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7KqBEcn_pyo"
      },
      "outputs": [],
      "source": [
        "# Function for one hot encoding\n",
        "\n",
        "def one_hot_encode_categorical_columns(df_encod):\n",
        "    # Identify categorical columns\n",
        "    categorical_columns = df_encod.select_dtypes(include=['object']).columns.tolist()\n",
        "    categorical_columns = [col for col in categorical_columns if col not in ('Date')]\n",
        "\n",
        "    # Perform one-hot encoding for each categorical column\n",
        "    for column in categorical_columns:\n",
        "        df_encod = pd.concat([df_encod, pd.get_dummies(df_encod[column], prefix=column, drop_first=True)], axis=1)\n",
        "        df_encod = df_encod.drop(column, axis=1)\n",
        "\n",
        "    return df_encod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_KIuLkI_pyp"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-MaT1Wp_pyp"
      },
      "outputs": [],
      "source": [
        "df_encoded=one_hot_encode_categorical_columns(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkT40VUz_pyq"
      },
      "outputs": [],
      "source": [
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxfTINpl_pyq"
      },
      "outputs": [],
      "source": [
        "df_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xj3AXKu_pys"
      },
      "outputs": [],
      "source": [
        "# Remvoving rows with NaN values:\n",
        "df_encoded=df_encoded.dropna()\n",
        "df_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d4fhaoH_pyt"
      },
      "outputs": [],
      "source": [
        "df_encoded.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dua2QkYY_pyt"
      },
      "outputs": [],
      "source": [
        "legit_data = df_encoded[df_encoded['Is Fraudulent'] == 0]\n",
        "fraud_data = df_encoded[df_encoded['Is Fraudulent'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_XDGtUf_pyu"
      },
      "outputs": [],
      "source": [
        "print(legit_data.shape)\n",
        "print(fraud_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGa-9Yrz_pyu"
      },
      "outputs": [],
      "source": [
        "legit_data.Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB-NiEky_pyv"
      },
      "outputs": [],
      "source": [
        "fraud_data.Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vuYDC2E_pyv"
      },
      "outputs": [],
      "source": [
        "df_encoded.groupby('Is Fraudulent').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZoZTj20_pyw"
      },
      "outputs": [],
      "source": [
        "# X defined with features other then target variable:\n",
        "X=df_encoded.drop(['Is Fraudulent','Date'],axis=1)\n",
        "\n",
        "\n",
        "# Y defined with the target variable\n",
        "Y=df_encoded['Is Fraudulent']\n",
        "\n",
        "# Split features and target variable\n",
        "#X = data_ml.drop(['Is Fraudulent','Date'], axis=1)\n",
        "#y = data_ml['Is Fraudulent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT1arRVl_pyw"
      },
      "outputs": [],
      "source": [
        "# SPlit training and testing data\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,stratify=Y, random_state=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFwu-76G_pyx"
      },
      "outputs": [],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcsPpwZu_pyx"
      },
      "outputs": [],
      "source": [
        "# Model Training\n",
        "# Logistic Regression\n",
        "\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "\n",
        "model.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BDDQ5Y__pyy"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "\n",
        "#Accuracy Score\n",
        "X_train_pred = model.predict(X_train)\n",
        "traininig_data_accuracy = accuracy_score(X_train_pred,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvlhqB_L_pyy"
      },
      "outputs": [],
      "source": [
        "print('Accuracy Training data:  ',traininig_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJLyTtkj_pyz"
      },
      "outputs": [],
      "source": [
        "# Accuracy on test data\n",
        "\n",
        "X_test_pred = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_pred, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ANuMtLw_pyz"
      },
      "outputs": [],
      "source": [
        "print('Accuracy score of Test data:  ',test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkHBmgeU_py0"
      },
      "outputs": [],
      "source": [
        "#Get Correlation of \"Churn\" with other variables annd recording the observations\n",
        "plt.figure(figsize=(15,8))\n",
        "df_encoded.corr()['Is Fraudulent'].sort_values(ascending = False).plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ylfdzT3_py0"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(data.corr(), cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBKcuqkI_py1"
      },
      "source": [
        "**4.Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLM5YFNZ_py1"
      },
      "source": [
        "a. Split the dataset into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9E7MucL_py2"
      },
      "outputs": [],
      "source": [
        "# Split features and target variable - Train = 80 % Test = 20%\n",
        "X = df_encoded.drop(['Is Fraudulent','Date'], axis=1)\n",
        "y = df_encoded['Is Fraudulent']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#Apply standard scalar\n",
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "LS9cd0TK_py2",
        "outputId": "61e549c3-a0af-4539-b610-a6f2b6f11fdf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3bb0f9c4cdcf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing data set: X_test: {X_test.shape}, y_test: {y_test.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\")\n",
        "print(f\"Testing data set: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78fK_een_py3"
      },
      "outputs": [],
      "source": [
        "# Get distributions - Calculate the percentage of each class in the training set\n",
        "train_class_percentage = y_train.value_counts(normalize=True) * 100\n",
        "print(\"Class distribution in Training Set:\")\n",
        "print(train_class_percentage)\n",
        "\n",
        "test_class_percentage = y_test.value_counts(normalize=True) * 100\n",
        "print(\"\\nClass distribution in Testing Set:\")\n",
        "print(test_class_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data split 45,55"
      ],
      "metadata": {
        "id": "gsF7Mm8VBWZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target variable - Train = 45 % Test = 55%\n",
        "X = df_encoded.drop(['Is Fraudulent','Date'], axis=1)\n",
        "y = df_encoded['Is Fraudulent']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#Apply standard scalar\n",
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "id": "PjXBm-yiBVXC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "CfnqEi_XB1J-",
        "outputId": "eda69825-3176-47c7-b229-b29c5eb0be44"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea46537ee38a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\")\n",
        "print(f\"Testing data set: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get distributions - Calculate the percentage of each class in the training set\n",
        "train_class_percentage = y_train.value_counts(normalize=True) * 100\n",
        "print(\"Class distribution in Training Set:\")\n",
        "print(train_class_percentage)\n",
        "\n",
        "test_class_percentage = y_test.value_counts(normalize=True) * 100\n",
        "print(\"\\nClass distribution in Testing Set:\")\n",
        "print(test_class_percentage)"
      ],
      "metadata": {
        "id": "vy9XPeluB7Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data split 60,40"
      ],
      "metadata": {
        "id": "w4S6N43dHGXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target variable - Train = 60 % Test = 40 %\n",
        "X = df_encoded.drop(['Is Fraudulent','Date'], axis=1)\n",
        "y = df_encoded['Is Fraudulent']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "#Apply standard scalar\n",
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "id": "31cf4Bc0HEir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "eda69825-3176-47c7-b229-b29c5eb0be44",
        "id": "MBqxCmmQHWWS"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea46537ee38a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"Training dataset: X_train: {X_train.shape}, y_train: {y_train.shape}\\n{'_'*58}\")\n",
        "print(f\"Testing data set: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get distributions - Calculate the percentage of each class in the training set\n",
        "train_class_percentage = y_train.value_counts(normalize=True) * 100\n",
        "print(\"Class distribution in Training Set:\")\n",
        "print(train_class_percentage)\n",
        "\n",
        "test_class_percentage = y_test.value_counts(normalize=True) * 100\n",
        "print(\"\\nClass distribution in Testing Set:\")\n",
        "print(test_class_percentage)"
      ],
      "metadata": {
        "id": "DS_M8TPDHblj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k59W0VKA_py3"
      },
      "source": [
        "As you we can see, this data set is highly imbalanced in favour of non fraudulent transactions. One way of dealing with this is by oversampling using SMOTE.\n",
        "\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) creates synthetic points close to other points, upsampling the minority class in order to reach an equal balance between the minority and majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4-CZSvf_py4"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE()\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X,y)\n",
        "#Class distribution\n",
        "print(\"Class distribution in the SMOTE oversampled training set:\")\n",
        "print(pd.Series(y_resampled_smote).value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb4Qb11b_py4"
      },
      "source": [
        "As well as oversampling, undersampling also addresses the issue of class imbalance by reducing the representation of the majority (non fraud) class in the data set.\n",
        "\n",
        "We will randomly remove classes from the majority class until there is balance.\n",
        "\n",
        "Following this, we will then be able to train the machine learning models on both of the data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3YBUavE_py5"
      },
      "outputs": [],
      "source": [
        "undersampler = RandomUnderSampler()\n",
        "X_resampled_under, y_resampled_under = undersampler.fit_resample(X, y)\n",
        "#Class distribution\n",
        "print(\"Class distribution in the Random undersampled training set:\")\n",
        "print(pd.Series(y_resampled_under).value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgnZ1URk_py5"
      },
      "outputs": [],
      "source": [
        "class_distr_before = pd.Series(y_train).value_counts(normalize=True) * 100\n",
        "smote_class_distr = pd.Series(y_resampled_smote).value_counts(normalize=True) * 100\n",
        "under_class_distr = pd.Series(y_resampled_under).value_counts(normalize=True) * 100\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.barplot(x=class_distr_before.index, y=class_distr_before.values)\n",
        "plt.title('Imbalanced class distribution')\n",
        "plt.xlabel('Is Fraudulent')\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.barplot(x=smote_class_distr.index, y=smote_class_distr.values)\n",
        "plt.title('SMOTE class distribution')\n",
        "plt.xlabel('Is Fraudulent')\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.barplot(x=under_class_distr.index, y=under_class_distr.values)\n",
        "plt.title('Random undersampling class distribution')\n",
        "plt.xlabel('Is Fraudulent')\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQcRCBIG_py6"
      },
      "source": [
        "Now that we have dealt with the imbalanced data we are able to build our model\n",
        "\n",
        "As this is a classification problem we will be building a logistic regression model, and also a decision tree model\n",
        "\n",
        "We will compare the scores of each model across the undersampled and oversampled data to see which one provides us with the best accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI1HcZDW_py7"
      },
      "source": [
        "# Logisitic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvzOoTSh_py8"
      },
      "outputs": [],
      "source": [
        "#Fit Both undersampled and oversampled data into logistic regression model and train it\n",
        "LogReg_smote = LogisticRegression(max_iter=7000) # Adjust max_iter as needed\n",
        "LogReg_under= LogisticRegression(max_iter=7000) # Adjust max_iter as needed\n",
        "\n",
        "LogReg_smote.fit(X_resampled_smote, y_resampled_smote)\n",
        "LogReg_under.fit(X_resampled_under, y_resampled_under)\n",
        "\n",
        "#Test and predict\n",
        "y_pred_smote = LogReg_smote.predict(X_resampled_smote)\n",
        "y_pred_under = LogReg_under.predict(X_resampled_under)\n",
        "\n",
        "roc_auc_smote = roc_auc_score(y_resampled_smote, y_pred_smote)\n",
        "roc_auc_under = roc_auc_score(y_resampled_under, y_pred_under)\n",
        "\n",
        "\n",
        "report_smote = classification_report(y_resampled_smote, y_pred_smote)\n",
        "print(\"Classification Report for Logistic Regression Model (SMOTE):\")\n",
        "print(report_smote)\n",
        "print(\"ROC AUC:\", roc_auc_smote)\n",
        "\n",
        "report_under = classification_report(y_resampled_under, y_pred_under)\n",
        "print(\"\\nClassification Report for Logistic Regression Model (Undersampling):\")\n",
        "print(report_under)\n",
        "print(\"ROC AUC:\", roc_auc_under)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6orEh8m_py8"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix for both models\n",
        "confusion_matrix_smote = confusion_matrix(y_resampled_smote, y_pred_smote)\n",
        "confusion_matrix_under = confusion_matrix(y_resampled_under, y_pred_under)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "#smote\n",
        "sns.heatmap(confusion_matrix_smote, annot=True, fmt='d', cmap=plt.cm.Oranges,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'], ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix (SMOTE Logistic Regression)')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "#undersampled\n",
        "sns.heatmap(confusion_matrix_under, annot=True, fmt='d', cmap=plt.cm.Blues,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'], ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix (Undersampled Logistic Regression)')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byrxqe8l_py9"
      },
      "source": [
        "<p>Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
        "\n",
        "True Positives (TP) – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
        "\n",
        "True Negatives (TN) – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
        "\n",
        "False Positives (FP) – False Positives occur when we predict an observation belongs to a certain class but the observation actually does not belong to that class. This type of error is called Type I error.\n",
        "\n",
        "False Negatives (FN) – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called Type II error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE5WpfiY_py9"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm_dt_smote = confusion_matrix(y_resampled_smote, y_pred_smote)\n",
        "\n",
        "conf_matrix_dt_smote = pd.DataFrame(data=cm_dt_smote, columns=['Non-Fraud:0', 'Fraud:1'], index=['Non-Fraud:0', 'Fraud:1'])\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(conf_matrix_dt_smote, annot=True, fmt='d',cmap=\"YlGnBu\")\n",
        "plt.title('Classification for Churn')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVuQe2d1_py-"
      },
      "outputs": [],
      "source": [
        "#Calculating measures for Logistic Regression based on our confusion matrix\n",
        "\n",
        "TP = conf_matrix_dt_smote.iloc[0, 0]\n",
        "TN = conf_matrix_dt_smote.iloc[1, 1]\n",
        "FN = conf_matrix_dt_smote.iloc[0, 1]\n",
        "FP = conf_matrix_dt_smote.iloc[1, 0]\n",
        "total = TP + TN + FN + FP\n",
        "\n",
        "print('Misclassification Rate: {:.1f}%'.format(100 * (FN + FP) / total))\n",
        "print('Recall: {:.1f}%'.format(100 * TP / (TP + FN)))\n",
        "print('Specificity: {:.1f}%'.format(100 * TN / (TN + FP)))\n",
        "print('Precision: {:.1f}%'.format(100 * TP / (FP + TP)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylufg3bY_py_"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm_dt_under = confusion_matrix(y_resampled_under, y_pred_under)\n",
        "\n",
        "conf_matrix_dt_under = pd.DataFrame(data=cm_dt_under, columns=['Non-Fraud:0', 'Fraud:1'], index=['Non-Fraud:0', 'Fraud:1'])\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(conf_matrix_dt_under, annot=True, fmt='d',cmap=\"YlGnBu\")\n",
        "plt.title('Classification for Churn')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxN_HExK_py_"
      },
      "outputs": [],
      "source": [
        "#Calculating measures for Logistic Regression based on our confusion matrix\n",
        "\n",
        "TP = conf_matrix_dt_under.iloc[0, 0]\n",
        "TN = conf_matrix_dt_under.iloc[1, 1]\n",
        "FN = conf_matrix_dt_under.iloc[0, 1]\n",
        "FP = conf_matrix_dt_under.iloc[1, 0]\n",
        "total = TP + TN + FN + FP\n",
        "\n",
        "print('Misclassification Rate: {:.1f}%'.format(100 * (FN + FP) / total))\n",
        "print('Recall: {:.1f}%'.format(100 * TP / (TP + FN)))\n",
        "print('Specificity: {:.1f}%'.format(100 * TN / (TN + FP)))\n",
        "print('Precision: {:.1f}%'.format(100 * TP / (FP + TP)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0mMN-UZ_pzA"
      },
      "outputs": [],
      "source": [
        "# Normalize the confusion matrices\n",
        "normalized_confusion_matrix_smote = confusion_matrix_smote / confusion_matrix_smote.sum(axis=1, keepdims=True)\n",
        "normalized_confusion_matrix_under = confusion_matrix_under / confusion_matrix_under.sum(axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(normalized_confusion_matrix_smote, annot=True, fmt='.2%', cmap=plt.cm.Oranges,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'], ax=axes[0], cbar=True)\n",
        "axes[0].set_title('Normalized Confusion Matrix (SMOTE Logistic Regression)')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "\n",
        "sns.heatmap(normalized_confusion_matrix_under, annot=True, fmt='.2%', cmap=plt.cm.Blues,\n",
        "            xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'], ax=axes[1], cbar=True)\n",
        "axes[1].set_title('Normalized Confusion Matrix (Undersampled Logistic Regression)')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcrD-aBo_pzB"
      },
      "source": [
        "# Fine-Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEN6EyAXp3LC"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHL3tRe1nZxz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "#Preprocessing: Encode categorical features\n",
        "label_encoders = {}\n",
        "for feature in data.columns:\n",
        "    if data[feature].dtype == 'object':\n",
        "        label_encoders[feature] = LabelEncoder()\n",
        "        data[feature] = label_encoders[feature].fit_transform(data[feature].astype(str))\n",
        "\n",
        "# Convert Timestamp data to numerical features\n",
        "#data['Date'] = data['Date'].astype('datetime64[ns]').astype(np.int64) // 10**9  # Convert Timestamp to Unix timestamp (seconds)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#X_train.drop(\"Date\", axis=1, inplace=True)\n",
        "#X_test.drop(\"Date\", axis=1, inplace=True)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Initialize Decision Tree classifier with best hyperparameters\n",
        "best_dt_classifier = DecisionTreeClassifier(**best_params, random_state=42)\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = best_dt_classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCQuPLO8qIuj"
      },
      "source": [
        "**5.Performance Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJZoyn9r_pzD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Split features and target variable\n",
        "X = df_encoded.drop('Is Fraudulent', axis=1)\n",
        "y = df_encoded['Is Fraudulent']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#X_train[\"Date\"] = X_train[\"Date\"].astype(float)\n",
        "#X_test[\"Date\"] = X_test[\"Date\"].astype(float)\n",
        "\n",
        "X_train.drop(\"Date\", axis=1, inplace=True)\n",
        "X_test.drop(\"Date\", axis=1, inplace=True)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lr_preds = lr_model.predict(X_test)\n",
        "dt_preds = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
        "lr_precision = precision_score(y_test, lr_preds, average='weighted',zero_division=1)\n",
        "lr_recall = recall_score(y_test, lr_preds, average='weighted')\n",
        "lr_f1 = f1_score(y_test, lr_preds, average='weighted')\n",
        "lr_roc_auc = roc_auc_score(y_test, lr_preds, average='weighted')\n",
        "\n",
        "# Evaluate Decision Tree model\n",
        "dt_accuracy = accuracy_score(y_test, dt_preds)\n",
        "dt_precision = precision_score(y_test, dt_preds, average='weighted',zero_division=1)\n",
        "dt_recall = recall_score(y_test, dt_preds, average='weighted')\n",
        "dt_f1 = f1_score(y_test, dt_preds, average='weighted')\n",
        "dt_roc_auc = roc_auc_score(y_test, dt_preds, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", lr_accuracy)\n",
        "print(\"Precision:\", lr_precision)\n",
        "print(\"Recall:\", lr_recall)\n",
        "print(\"F1-score:\", lr_f1)\n",
        "print(\"ROC-AUC score:\", lr_roc_auc)\n",
        "\n",
        "print(\"\\nDecision Tree Metrics:\")\n",
        "print(\"Accuracy:\", dt_accuracy)\n",
        "print(\"Precision:\", dt_precision)\n",
        "print(\"Recall:\", dt_recall)\n",
        "print(\"F1-score:\", dt_f1)\n",
        "print(\"ROC-AUC score:\", dt_roc_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3rcbLwY_pzD"
      },
      "source": [
        "# Assignment Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-RS-cyf_pzE"
      },
      "source": [
        "## 1. Model Building\n",
        "## Build ML models using K-Nearest Neighbors (K-NN), Support Vector Machine (SVM), Naive Bayesian, Random Forest, and Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERIdbrBlCoPC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Convert 'Date' column to datetime\n",
        "#df_encoded[\"Date\"] = pd.to_datetime(df_encoded[\"Date\"])\n",
        "\n",
        "# Perform one-hot encoding on categorical variables\n",
        "#data = pd.get_dummies(data, columns=['Card Type', 'MCC Category', 'Location', 'Device', 'Merchant Reputation', 'Online Transactions Frequency'])\n",
        "\n",
        "\n",
        "\n",
        "# Split features and target variable\n",
        "X = df_encoded.drop('Is Fraudulent', axis=1)\n",
        "y = df_encoded['Is Fraudulent']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#X_train[\"Date\"] = X_train[\"Date\"].astype(float)\n",
        "#X_test[\"Date\"] = X_test[\"Date\"].astype(float)\n",
        "\n",
        "X_train.drop(\"Date\", axis=1, inplace=True)\n",
        "X_test.drop(\"Date\", axis=1, inplace=True)\n",
        "\n",
        "# Scale numerical features\n",
        "#scaler = StandardScaler()\n",
        "#X_train_scaled = scaler.fit_transform(X_train)\n",
        "#X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# K-Nearest Neighbors (K-NN)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "# Training the algorithm and prediction on testing data & Evaluation\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "lr_precision = precision_score(y_test, knn_pred,zero_division=1)\n",
        "print(\"Precision Score:\", lr_precision)\n",
        "lr_recall = recall_score(y_test, knn_pred)\n",
        "print(\"Precision Score:\", lr_recall)\n",
        "lr_f1 = f1_score(y_test, knn_pred)\n",
        "print(\"Precision Score:\", lr_f1)\n",
        "\n",
        "\n",
        "#Support Vector Machine\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "svc_precision = precision_score(y_test, svm_pred,zero_division=1)\n",
        "print(\"Precision Score:\", svc_precision)\n",
        "svc_recall = recall_score(y_test, svm_pred)\n",
        "print(\"Precision Score:\", svc_recall)\n",
        "svc_f1 = f1_score(y_test, svm_pred)\n",
        "print(\"Precision Score:\", svc_f1)\n",
        "\n",
        "\n",
        "# Naive Bayesian\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_test)\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayesian Accuracy:\", nb_accuracy)\n",
        "nb_precision = precision_score(y_test, nb_pred,zero_division=1)\n",
        "print(\"Precision Score:\", nb_precision)\n",
        "nb_recall = recall_score(y_test, nb_pred)\n",
        "print(\"Precision Score:\", nb_recall)\n",
        "nb_f1 = f1_score(y_test, nb_pred)\n",
        "print(\"Precision Score:\", nb_f1)\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "rf_precision = precision_score(y_test, rf_pred,zero_division=1)\n",
        "print(\"Precision Score:\", rf_precision)\n",
        "rf_recall = recall_score(y_test, rf_pred)\n",
        "print(\"Precision Score:\", rf_recall)\n",
        "rf_f1 = f1_score(y_test, rf_pred)\n",
        "print(\"Precision Score:\", rf_f1)\n",
        "\n",
        "\n",
        "\n",
        "# Adaboost\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada.fit(X_train, y_train)\n",
        "ada_pred = ada.predict(X_test)\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "print(\"Adaboost Accuracy:\", ada_accuracy)\n",
        "ada_precision = precision_score(y_test, ada_pred,zero_division=1)\n",
        "print(\"Precision Score:\", ada_precision)\n",
        "ada_recall = recall_score(y_test, ada_pred)\n",
        "print(\"Precision Score:\", ada_recall)\n",
        "ada_f1 = f1_score(y_test, ada_pred)\n",
        "print(\"Precision Score:\", ada_f1)\n",
        "\n",
        "\n",
        "# For regression\n",
        "k = 5  # number of neighbors to consider\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
        "\n",
        "\n",
        "\n",
        "# For regression\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# For regression\n",
        "y_pred_reg = knn_regressor.predict(X_test)\n",
        "\n",
        "\n",
        "# For regression\n",
        "mse = mean_squared_error(y_test, y_pred_reg)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\"\"\"\n",
        "# Example of hyperparameter tuning for classification\n",
        "for k in range(1, 11):\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    y_pred_class = knn_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred_class)\n",
        "    print(\"K =\", k, \"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "#model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test,zero_division=1))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgYqP1NX_pzF"
      },
      "outputs": [],
      "source": [
        "# K-Nearest Neighbors (K-NN)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "# Training the algorithm and prediction on testing data & Evaluation\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "lr_precision = precision_score(y_test, knn_pred,zero_division=1)\n",
        "print(\"Precision Score:\", lr_precision)\n",
        "lr_recall = recall_score(y_test, knn_pred)\n",
        "print(\"Recall:\", lr_recall)\n",
        "lr_f1 = f1_score(y_test, knn_pred)\n",
        "print(\"F1 Score:\", lr_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d4iJlDA_pzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, knn_pred,zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGDV2T8L_pzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "LABELS=['Non-Fraud', 'Fraud']\n",
        "# Create confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test, knn_pred)\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(1,  figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=LABELS, yticklabels=LABELS)\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWGNs5I__pzH"
      },
      "outputs": [],
      "source": [
        "# 3) Fine-Tuning Hyperparameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for K-NN\n",
        "param_grid_knn = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
        "\n",
        "# Initialize K-NN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Initialize GridSearchCV with K-NN classifier and parameter grid\n",
        "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best accuracy score\n",
        "best_params_knn = grid_search_knn.best_params_\n",
        "best_score_knn = grid_search_knn.best_score_\n",
        "\n",
        "print(\"Best Parameters for K-NN:\", best_params_knn)\n",
        "print(\"Best Accuracy Score for K-NN:\", best_score_knn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDRoVfj1_pzH"
      },
      "outputs": [],
      "source": [
        "#Support Vector Machine\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "svc_precision = precision_score(y_test, svm_pred,zero_division=1)\n",
        "print(\"Precision Score:\", svc_precision)\n",
        "svc_recall = recall_score(y_test, svm_pred)\n",
        "print(\"Recall:\", svc_recall)\n",
        "svc_f1 = f1_score(y_test, svm_pred)\n",
        "print(\"F1 Score:\", svc_f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T010zXAS_pzI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, svm_pred,zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb86suDF_pzI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "LABELS=['Non-Fraud', 'Fraud']\n",
        "# Create confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test, svm_pred)\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(1,  figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=LABELS, yticklabels=LABELS)\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-0Jji48_pzJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(y_test, svm_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bj9_BCk_pzJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title('ROC Curve', fontsize=15)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.xticks(np.arange(0, 1, 0.05), rotation=90)\n",
        "    plt.xlabel('False Positive Rates', fontsize=15)\n",
        "    plt.ylabel('True Positive Rates', fontsize=15)\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8k9eFyb_pzK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# First, getting the auc score\n",
        "svc_auc = roc_auc_score(y_test, svm_pred)\n",
        "\n",
        "# Now, let's get the fpr and tpr\n",
        "fpr, tpr, threshold = roc_curve(y_test, svm_pred)\n",
        "\n",
        "# Now, let's draw the curve\n",
        "plot_roc_curve(fpr, tpr, 'AUC: %.3f' % svc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMrnDmAz_pzL"
      },
      "outputs": [],
      "source": [
        "#Tune Hyperparameters\n",
        "\n",
        "# For Kernel = rbf\n",
        "tuned_rbf = {'kernel': ['rbf'], 'gamma': [\n",
        "    1e-2, 1e-3, 1e-4, 1e-5], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}\n",
        "\n",
        "# For kernel = sigmoid\n",
        "tuned_sigmoid = {'kernel': ['sigmoid'], 'gamma': [\n",
        "    1e-2, 1e-3, 1e-4, 1e-5], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}\n",
        "\n",
        "# For kernel = linear\n",
        "tuned_linear = {'kernel': ['linear'], 'C': [\n",
        "    0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTr-vNtW_pzM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rs_rbf = RandomizedSearchCV(estimator=SVC(probability=True),\n",
        "        param_distributions=tuned_rbf, n_iter=500, n_jobs=4, scoring='roc_auc')\n",
        "\n",
        "rs_sigmoid = RandomizedSearchCV(estimator=SVC(probability=True),\n",
        "        param_distributions=tuned_sigmoid, n_iter=500, n_jobs=4, scoring='roc_auc')\n",
        "\n",
        "rs_linear = RandomizedSearchCV(estimator=SVC(probability=True),\n",
        "        param_distributions=tuned_linear, n_iter=500, n_jobs=4, scoring='roc_auc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyIYx3N8_pzN"
      },
      "source": [
        "**For kernel rbf:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7FVyo5O_pzN"
      },
      "outputs": [],
      "source": [
        "rs_rbf.fit(X_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btSlGGSR_pzO"
      },
      "outputs": [],
      "source": [
        "# Naive Bayesian\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_test)\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayesian Accuracy:\", nb_accuracy)\n",
        "nb_precision = precision_score(y_test, nb_pred,zero_division=1)\n",
        "print(\"Precision Score:\", nb_precision)\n",
        "nb_recall = recall_score(y_test, nb_pred)\n",
        "print(\"Recall:\", nb_recall)\n",
        "nb_f1 = f1_score(y_test, nb_pred)\n",
        "print(\"F1:\", nb_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm_dgk3m_pzO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, nb_pred,zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCpQRpul_pzP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "LABELS=['Non-Fraud', 'Fraud']\n",
        "# Create confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test, nb_pred)\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(1,  figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=LABELS, yticklabels=LABELS)\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXJgHIwK_pzP"
      },
      "outputs": [],
      "source": [
        "# 3) Fine-Tuning Hyperparameters\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the parameter grid for Naive Bayes\n",
        "param_grid_nb = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7]  # Adjust var_smoothing parameter\n",
        "}\n",
        "\n",
        "# Initialize Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Initialize GridSearchCV with Naive Bayes classifier and parameter grid\n",
        "grid_search_nb = GridSearchCV(nb, param_grid_nb, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search_nb.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best accuracy score\n",
        "best_params_nb = grid_search_nb.best_params_\n",
        "best_score_nb = grid_search_nb.best_score_\n",
        "\n",
        "print(\"Best Parameters for Naive Bayes:\", best_params_nb)\n",
        "print(\"Best Accuracy Score for Naive Bayes:\", best_score_nb)\n",
        "\n",
        "# Use the best parameters to train the final Naive Bayes model\n",
        "nb_best = GaussianNB(var_smoothing=best_params_nb['var_smoothing'])\n",
        "nb_best.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the final model\n",
        "nb_pred = nb_best.predict(X_test)\n",
        "\n",
        "# Evaluate the final model\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayesian Accuracy:\", nb_accuracy)\n",
        "nb_precision = precision_score(y_test, nb_pred, zero_division=1)\n",
        "print(\"Precision Score:\", nb_precision)\n",
        "nb_recall = recall_score(y_test, nb_pred)\n",
        "print(\"Recall:\", nb_recall)\n",
        "nb_f1 = f1_score(y_test, nb_pred)\n",
        "print(\"F1:\", nb_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ0TGoRL_pzQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "rf_precision = precision_score(y_test, rf_pred,zero_division=1)\n",
        "print(\"Precision Score:\", rf_precision)\n",
        "rf_recall = recall_score(y_test, rf_pred)\n",
        "print(\"Recall:\", rf_recall)\n",
        "rf_f1 = f1_score(y_test, rf_pred)\n",
        "print(\"F1:\", rf_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmYrevom_pzQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, rf_pred,zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQo0PQAz_pzR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "LABELS=['Non-Fraud', 'Fraud']\n",
        "# Create confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test, rf_pred)\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(1,  figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=LABELS, yticklabels=LABELS)\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNY5X-kO_pzR"
      },
      "outputs": [],
      "source": [
        "# 3) Fine-Tuning Hyperparameters\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV with Random Forest classifier and parameter grid\n",
        "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best accuracy score\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "best_score_rf = grid_search_rf.best_score_\n",
        "\n",
        "print(\"Best Parameters for Random Forest:\", best_params_rf)\n",
        "print(\"Best Accuracy Score for Random Forest:\", best_score_rf)\n",
        "\n",
        "# Use the best parameters to train the final Random Forest model\n",
        "rf_best = RandomForestClassifier(random_state=42, **best_params_rf)\n",
        "rf_best.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the final model\n",
        "rf_pred = rf_best.predict(X_test)\n",
        "\n",
        "# Evaluate the final model\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "rf_precision = precision_score(y_test, rf_pred, zero_division=1)\n",
        "print(\"Precision Score:\", rf_precision)\n",
        "rf_recall = recall_score(y_test, rf_pred)\n",
        "print(\"Recall:\", rf_recall)\n",
        "rf_f1 = f1_score(y_test, rf_pred)\n",
        "print(\"F1:\", rf_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvE7CMZp_pzS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Adaboost\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada.fit(X_train, y_train)\n",
        "ada_pred = ada.predict(X_test)\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "print(\"Adaboost Accuracy:\", ada_accuracy)\n",
        "ada_precision = precision_score(y_test, ada_pred,zero_division=1)\n",
        "print(\"Precision Score:\", ada_precision)\n",
        "ada_recall = recall_score(y_test, ada_pred)\n",
        "print(\"Recall:\", ada_recall)\n",
        "ada_f1 = f1_score(y_test, ada_pred)\n",
        "print(\"F1:\", ada_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcuEPV9S_pzS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, ada_pred,zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoE5cGmr_pzT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
        "#Model evaluation based on K-fold cross-validation using cross_val_score() function\n",
        "# 10-fold cross-validation logistic regression\n",
        "ada_fold = AdaBoostClassifier()\n",
        "# Use cross_val_score function\n",
        "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n",
        "# cv=10 for 10 folds\n",
        "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
        "scores_accuracy = cross_val_score(ada_fold, X_train, y_train, cv=10, scoring='accuracy')\n",
        "scores_log_loss = cross_val_score(ada_fold, X_train, y_train, cv=10, scoring='neg_log_loss')\n",
        "scores_auc = cross_val_score(ada_fold, X_train, y_train, cv=10, scoring='roc_auc')\n",
        "print('K-fold cross-validation results:')\n",
        "print(ada_fold.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
        "print(ada_fold.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
        "print(ada_fold.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijCFPqsS_pzT"
      },
      "outputs": [],
      "source": [
        "#Model evaluation based on K-fold cross-validation using cross_validate() function\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n",
        "\n",
        "modelCV = AdaBoostClassifier()\n",
        "\n",
        "results = cross_validate(modelCV, X_train, y_train, cv=10, scoring=list(scoring.values()),\n",
        "                         return_train_score=False)\n",
        "\n",
        "print('K-fold cross-validation results:')\n",
        "for sc in range(len(scoring)):\n",
        "    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n",
        "                               if list(scoring.values())[sc]=='neg_log_loss'\n",
        "                               else results['test_%s' % list(scoring.values())[sc]].mean(),\n",
        "                               results['test_%s' % list(scoring.values())[sc]].std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK3LMeTZ_pzU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "LABELS=['Non-Fraud', 'Fraud']\n",
        "# Create confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test, ada_pred)\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(1,  figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='viridis',\n",
        "            xticklabels=LABELS, yticklabels=LABELS)\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "\n",
        "\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xIiUN_7_pzU"
      },
      "outputs": [],
      "source": [
        "# 3) Fine-Tuning Hyperparameters\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the parameter grid for AdaBoostClassifier\n",
        "param_grid_ada = {\n",
        "    'n_estimators': [50, 100, 200],           # Number of weak learners\n",
        "    'learning_rate': [0.01, 0.1, 1.0]         # Learning rate\n",
        "}\n",
        "\n",
        "# Initialize AdaBoostClassifier\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV with AdaBoostClassifier and parameter grid\n",
        "grid_search_ada = GridSearchCV(ada, param_grid_ada, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search_ada.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best accuracy score\n",
        "best_params_ada = grid_search_ada.best_params_\n",
        "best_score_ada = grid_search_ada.best_score_\n",
        "\n",
        "print(\"Best Parameters for AdaBoost:\", best_params_ada)\n",
        "print(\"Best Accuracy Score for AdaBoost:\", best_score_ada)\n",
        "\n",
        "# Use the best parameters to train the final AdaBoost model\n",
        "ada_best = AdaBoostClassifier(random_state=42, **best_params_ada)\n",
        "ada_best.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the final model\n",
        "ada_pred = ada_best.predict(X_test)\n",
        "\n",
        "# Evaluate the final model\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "print(\"AdaBoost Accuracy:\", ada_accuracy)\n",
        "ada_precision = precision_score(y_test, ada_pred, zero_division=1)\n",
        "print(\"Precision Score:\", ada_precision)\n",
        "ada_recall = recall_score(y_test, ada_pred)\n",
        "print(\"Recall:\", ada_recall)\n",
        "ada_f1 = f1_score(y_test, ada_pred)\n",
        "print(\"F1:\", ada_f1)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}